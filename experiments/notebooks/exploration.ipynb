{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d75f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def explore_spotify_data():\n",
    "    \"\"\"\n",
    "    Connects to S3, lists available daily Parquet files,\n",
    "    and loads the most recent one into a Pandas DataFrame for exploration.\n",
    "    \"\"\"\n",
    "    # --- 1. Setup and S3 Connection ---\n",
    "    print(\"--- Setting up S3 connection ---\")\n",
    "    \n",
    "    # Load credentials from the .env file in the parent directory\n",
    "    load_dotenv('../.env')\n",
    "\n",
    "    # S3 Configuration\n",
    "    s3_endpoint_url = os.getenv('AWS_ENDPOINT_URL')\n",
    "    s3_bucket_name = 'inbound'  # Or your bucket name\n",
    "    s3_prefix = 'raw/spotify/api/daily/'\n",
    "\n",
    "    if not s3_endpoint_url:\n",
    "        print(\"Error: AWS_ENDPOINT_URL not found in .env file.\")\n",
    "        return\n",
    "\n",
    "    # Create an S3 filesystem object\n",
    "    try:\n",
    "        s3 = s3fs.S3FileSystem(\n",
    "            client_kwargs={\n",
    "                'endpoint_url': s3_endpoint_url\n",
    "            }\n",
    "        )\n",
    "        print(\"S3 filesystem object created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating S3 filesystem object: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. List Available Data Files ---\n",
    "    print(\"\\n--- Listing available data files ---\")\n",
    "    parquet_files = []\n",
    "    try:\n",
    "        full_path = f'{s3_bucket_name}/{s3_prefix}'\n",
    "        print(f'Listing files in: s3://{full_path}')\n",
    "        available_files = s3.ls(full_path)\n",
    "        \n",
    "        parquet_files = sorted([f for f in available_files if f.endswith('.parquet')])\n",
    "        \n",
    "        if not parquet_files:\n",
    "            print(\"\\nNo Parquet files found in the specified directory.\")\n",
    "        else:\n",
    "            print(\"\\nAvailable Parquet files:\")\n",
    "            for f in parquet_files:\n",
    "                print(f'- s3://{f}')\n",
    "    except Exception as e:\n",
    "        print(f\"Could not list files: {e}\")\n",
    "\n",
    "    # --- 3. Load and Analyze the Most Recent File ---\n",
    "    print(\"\\n--- Loading and analyzing the most recent file ---\")\n",
    "    if parquet_files:\n",
    "        # Choose the last file in the sorted list, which should be the most recent\n",
    "        file_to_load = parquet_files[-1]\n",
    "        \n",
    "        print(f\"Loading data from: s3://{file_to_load}...\")\n",
    "        try:\n",
    "            # Use the s3fs object to open the file\n",
    "            with s3.open(file_to_load, 'rb') as f:\n",
    "                df = pd.read_parquet(f)\n",
    "            \n",
    "            print(\"\\nSuccessfully loaded DataFrame!\")\n",
    "            \n",
    "            print(\"\\nDataFrame Info:\")\n",
    "            df.info()\n",
    "            \n",
    "            print(\"\\nFirst 5 Rows:\")\n",
    "            print(df.head())\n",
    "            \n",
    "            print(f\"\\nTotal tracks on this day: {len(df)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Parquet file: {e}\")\n",
    "    else:\n",
    "        print(\"No files found to load.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    explore_spotify_data()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
